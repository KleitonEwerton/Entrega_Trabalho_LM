# Modelos de Linguagem com SRILM - Experimentos e An√°lise

Este reposit√≥rio cont√©m os scripts e logs dos experimentos realizados para a disciplina de Modelos de Linguagem. O projeto foca na an√°lise do impacto de diferentes m√©todos de suaviza√ß√£o (Smoothing) em corpora esparsos de l√≠ngua portuguesa.

**Aluno:** Kleiton Ewerton
**Data:** Novembro/2025

## üìÇ Estrutura do Projeto

* `src/` (ou raiz): Scripts Python para ETL e avalia√ß√£o.
* `imagens/`: Prints do terminal utilizados no relat√≥rio para comprovar a execu√ß√£o.
* `results/`: Logs de sa√≠da do SRILM e prints comprobat√≥rios.
* `treino.txt` / `teste.txt`: Corpus gerado a partir da Wikipedia PT.

## üõ†Ô∏è Pr√©-requisitos

1. **SRILM Toolkit:** Deve estar instalado e configurado no PATH.
   * Compilado com `MACHINE_TYPE=i686-m64`.
2. **Python 3.8+**
3. **Depend√™ncias Python:**
   ```bash
   pip install -r requirements.txt
## üöÄ Como Executar

Abaixo est√£o as instru√ß√µes para reproduzir o pipeline de dados, treinamento e avalia√ß√£o.

### 1. Prepara√ß√£o dos Dados (ETL)
O script baixa artigos da Wikipedia, normaliza o texto e realiza o *split* rigoroso (80/20). Se desejar gerar novos dados:

```bash
python3 preparar_dados.py
```

### 2. Experimentos de Perplexidade (SRILM)
Exemplos de comandos utilizados para treinar modelos e avaliar a Perplexidade (PPL).

Baseline (Sem suaviza√ß√£o):

```bash
ngram-count -text treino.txt -order 3 -addsmooth 0 -lm baseline.lm
```
ngram -lm baseline.lm -ppl teste.txt
Melhor Modelo (Kneser-Ney):

```bash
ngram-count -text treino.txt -order 3 -kndiscount -lm kneser.lm
ngram -lm kneser.lm -ppl teste.txt
```
### 3. Scripts de Avalia√ß√£o Emp√≠rica
Visualiza√ß√£o de Shannon (Gera√ß√£o de Frases): Gera senten√ßas aleat√≥rias baseadas nas probabilidades de n-grams do modelo treinado.

```bash
python3 shannon_viz.py
```
Teste de Acur√°cia (Good vs Bad Sentences): Verifica se o modelo atribui menor perplexidade (maior probabilidade) a frases gramaticalmente corretas em compara√ß√£o a frases sem sentido.

```bash
python3 avaliacao_empirica.py
```
Classificador de T√≥picos (Extra): Demonstra√ß√£o de classifica√ß√£o de texto (Esporte vs. M√∫sica) via compara√ß√£o de Perplexidade.

```bash
python3 classificador_topicos.py
```
## üì¶ Conte√∫do do Pacote de Entrega
A estrutura deste diret√≥rio de entrega est√° organizada da seguinte forma:

### Scripts Python (.py):

 - preparar_dados.py: ETL e limpeza de dados.

 - shannon_viz.py: Gerador de texto.

 - avaliacao_empirica.py: Valida√ß√£o de acur√°cia.

 - classificador_topicos.py: Experimento extra de classifica√ß√£o.

### Configura√ß√£o:

 - requirements.txt: Lista de depend√™ncias Python (instalar com pip install -r requirements.txt).

 - README.md: Este arquivo de documenta√ß√£o.

 - Evid√™ncias e Logs (.txt):

 - resultado_*.txt: Logs contendo as sa√≠das do terminal com valores de Perplexidade e ZeroProbs.

### Figuras:

Prints do terminal utilizados no relat√≥rio para comprovar a execu√ß√£o.

### Documenta√ß√£o Final:

Relatorio.pdf: Relat√≥rio t√©cnico completo (gerado via LaTeX/Overleaf).
